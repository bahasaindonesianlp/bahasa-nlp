## Meeting 1

Date: 2020-01-05, 8PM PT  
Attendee(s): Anthony, Moorissa

### Goal setting
**Audacious Goal**  
A single, comprehensive toolkit for NLP in Bahasa Indonesia with the following features:
* [ ] Tokenization
* [ ] Word-stemming / lemmatization
* [ ] Part of Speech tagging
* [ ] Vectorization
* [ ] Named Entity Recognizer

Possibly:
* A classifier for super common news-y type data, such as Sports, Politics, Economics, Business (etc)
* How can we scale our tool for different dialects?

**Objectives**
* Trained on open data
* Data should be in one place
* Create a reproducible pipeline that takes the data, trains the model (and copes with new / updated versions of the datasets)
* Open source
* Preferably contributed to an upstream library

### Resources
* Example: https://malaya.readthedocs.io/
* Tokenization
  * Open annotated dataset: https://universaldependencies.org/ (141k words)
  * https://github.com/UniversalDependencies/UD_Indonesian-GSD
* Lemmatization:
  * Neural-net based lemmatizer library: https://github.com/Hyperparticle/neural-lemmatizer-allennlp (more info at Medium TDS)
* Part of Speech Tagging
  * Open annotated dataset: https://universaldependencies.org/ (141k words)
(But check exactly what POS they are)
* Word Vectors:
  * Fasttext already produce this, but we need a way of doing it ourselves (So we can contribute it as a single pipeline to Spacy) - https://fasttext.cc/docs/en/crawl-vectors.html
  * Trained on https://commoncrawl.org/ and http://id.wikipedia.org
* Mixed:
  * https://medium.com/@arie.pratama.s/bahasa-indonesia-open-sourced-nlp-resources-8cb394193238
* Named Entity Recognition
  * NER lib for Bahasa: https://polyglot.readthedocs.io/en/latest/NamedEntityRecognition.html
  * No idea yet: https://medium.com/@arie.pratama.s/bahasa-indonesia-open-sourced-nlp-resources-8cb394193238
  * Crazy idea: Can we train a named entity recognizer from Wikipedia data?
https://arxiv.org/pdf/1812.09449.pdf


### To-do list
* [x] Set up a giant repository: [bahasa-nlp](https://github.com/bahasaindonesianlp/bahasa-nlp)
* [ ] Start putting all the various datasets in there
* [ ] Letâ€™s use the Github Issues to map out the first 10-11 tasks
* [ ] Set up a time for a weekend hack
